Traceback (most recent call last):
  File "/zhome/32/9/137127/Master-Thesis/scripts/lotka-volterra-upinn.py", line 153, in <module>
    optimizer.step(closure)  # Pass the closure to the optimizer
    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/zhome/32/9/137127/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py", line 487, in wrapper
    out = func(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/zhome/32/9/137127/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py", line 91, in _use_grad
    ret = func(self, *args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/zhome/32/9/137127/.venv/lib/python3.11/site-packages/torch/optim/adamw.py", line 197, in step
    loss = closure()
           ^^^^^^^^^
  File "/zhome/32/9/137127/Master-Thesis/scripts/lotka-volterra-upinn.py", line 139, in closure
    lambda_ = SoftAdapt(losses, torch.tensor([ic_loss, pde_loss, data_loss], device=device), beta=0.1)
                        ^^^^^^
UnboundLocalError: cannot access local variable 'losses' where it is not associated with a value
