{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the script (i.e., project/) to sys.path\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.bvp import BVP\n",
    "from utils.upinn import UPINN\n",
    "from utils.DataGenerators import LotkaVolterra, sample_with_noise\n",
    "from utils.architectures import FNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "### Generate data from Lotka-Volterra model ###\n",
    "###############################################\n",
    "###   dx/dt = alpha*x - beta*x*y            ###\n",
    "###   dy/dt = gamma*x*y - delta*y           ###\n",
    "###############################################\n",
    "alpha, beta, gamma, delta = 2/3, 4/3, 1.0, 1.0\n",
    "x0, y0 = 1.0, 1.0\n",
    "LV = LotkaVolterra(alpha, beta, gamma, delta, torch.tensor([x0, y0], dtype=torch.float32))\n",
    "\n",
    "time_int = [0, 25]\n",
    "train_test = 0.8\n",
    "N = 800\n",
    "t = torch.linspace(time_int[0], time_int[1], N)\n",
    "X = LV.solve(t)\n",
    "train_idx = torch.arange(0, train_test*N, dtype=torch.long)\n",
    "test_idx = torch.arange(train_test*N, N, dtype=torch.long)\n",
    "\n",
    "# Sample subset and add noise\n",
    "t_d, X_d = sample_with_noise(10, t[train_idx], X[train_idx], epsilon=5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Boundary Value Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LV_BVP(BVP):\n",
    "    \n",
    "    def __init__(self, params):\n",
    "        super().__init__(params)\n",
    "\n",
    "    def f(self, z, U):\n",
    "        alpha = self.params['alpha'] if 'alpha' in self.params else self.alpha\n",
    "        beta = self.params['beta'] if 'beta' in self.params else self.beta\n",
    "        delta = self.params['delta'] if 'delta' in self.params else self.delta\n",
    "\n",
    "        dUdt = torch.cat([\n",
    "        torch.autograd.grad(outputs=U[:, i], inputs=z, grad_outputs=torch.ones_like(U[:, i]), create_graph=True)[0]\n",
    "        for i in range(U.shape[1])\n",
    "        ], dim=-1)\n",
    "\n",
    "        return torch.stack([\n",
    "            dUdt[:, 0] - alpha*U[:, 0] + beta*U[:, 0]*U[:, 1],\n",
    "            dUdt[:, 1] + delta*U[:, 1] # - gamma*U[:, 0]*U[:, 1] <-- Estimate this\n",
    "        ], dim=-1)\n",
    "    \n",
    "\n",
    "    def g(self, z, U):\n",
    "        return U - 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup UPINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model architectures\n",
    "hidden = [16] * 4\n",
    "u = FNN(\n",
    "    dims=[1, *hidden, 2],\n",
    "    hidden_act=torch.nn.Tanh(),\n",
    "    output_act=torch.nn.Softplus(),\n",
    ")\n",
    "G = FNN(\n",
    "    dims=[2, *hidden, 2],\n",
    "    hidden_act=torch.nn.Tanh(),\n",
    "    output_act=torch.nn.ReLU(),\n",
    ")\n",
    "\n",
    "# Setup scaling layer\n",
    "u.scale_fn = lambda t_: (t_-t.min())/(t.max()-t.min())\n",
    "mu, sigma = 0, 2\n",
    "epsilon = 1e-8\n",
    "G.scale_fn = lambda x: (x-mu)/(sigma+epsilon)\n",
    "\n",
    "# Define model\n",
    "# params = dict(\n",
    "#     alpha=torch.nn.Parameter(torch.tensor(0.5)),\n",
    "#     beta=torch.nn.Parameter(torch.tensor(0.5)),\n",
    "#     delta=torch.nn.Parameter(torch.tensor(0.5))\n",
    "# )\n",
    "params = dict(\n",
    "    alpha=alpha,\n",
    "    beta=beta,\n",
    "    delta=delta,\n",
    ")\n",
    "\n",
    "\n",
    "upinn = UPINN(u, G, bvp=LV_BVP(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "class LV_Plotter:\n",
    "    def __init__(self, t, X, t_d, X_d, gamma):\n",
    "        self.t = t\n",
    "        self.X = X\n",
    "        self.z_d = t_d\n",
    "        self.U_d = X_d\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def __call__(self, u, G):\n",
    "        device = next(u.parameters()).device # Get the device of the model\n",
    "        plots = dict()\n",
    "\n",
    "        # Evaluate the model\n",
    "        X_pred = u(self.t.unsqueeze(-1).to(device))\n",
    "\n",
    "        # Plot with plotly\n",
    "        fig = go.Figure()\n",
    "        fig.add_scatter(x=self.t.cpu().numpy(), y=self.X[:, 0].cpu().numpy(), mode='lines', name='Prey', line=dict(dash='dash', color='green'))\n",
    "        fig.add_scatter(x=self.t.cpu().numpy(), y=self.X[:, 1].cpu().numpy(), mode='lines', name='Predator', line=dict(dash='dash', color='red'))\n",
    "        fig.add_scatter(x=self.t.cpu().numpy(), y=X_pred[:, 0].cpu().numpy(), mode='lines', name='Prey (pred)', line=dict(color='green'))\n",
    "        fig.add_scatter(x=self.t.cpu().numpy(), y=X_pred[:, 1].cpu().numpy(), mode='lines', name='Predator (pred)', line=dict(color='red'))\n",
    "        # Add datapoints\n",
    "        fig.add_scatter(x=self.z_d.squeeze().cpu().numpy(), y=self.U_d[:, 0].cpu().numpy(), mode='markers', name='Prey (data)', marker=dict(color='green', symbol='x'))\n",
    "        fig.add_scatter(x=self.z_d.squeeze().cpu().numpy(), y=self.U_d[:, 1].cpu().numpy(), mode='markers', name='Predator (data)', marker=dict(color='red', symbol='x'))\n",
    "        fig.update_layout(title=f\"Lotka-Volterra Model\")\n",
    "        \n",
    "        # Log figure to wandb\n",
    "        plots[\"Solution\"] = fig\n",
    "\n",
    "        # Plot missing terms\n",
    "        res = G(X_pred).cpu()\n",
    "        res_dx = res[:, 0]\n",
    "        res_dy = res[:, 1]\n",
    "        true_res_dx = torch.zeros_like(res_dx)\n",
    "        true_res_dy = (self.gamma*self.X[:, 0]*self.X[:, 1]).cpu().numpy()\n",
    "\n",
    "        fig = go.Figure()\n",
    "        fig.add_scatter(x=self.t.cpu().numpy(), y=res_dx, mode='lines', name='Residual Prey', line=dict(color='green'))\n",
    "        fig.add_scatter(x=self.t.cpu().numpy(), y=res_dy, mode='lines', name='Residual Predator', line=dict(color='red'))\n",
    "        fig.add_scatter(x=self.t.cpu().numpy(), y=true_res_dx, mode='lines', name='Prey: 0', line=dict(dash='dash', color='green'))\n",
    "        fig.add_scatter(x=self.t.cpu().numpy(), y=true_res_dy, mode='lines', name='Predator: Î³*x*y', line=dict(dash='dash', color='red'))\n",
    "        fig.update_layout(title=f\"Lotka-Volterra Missing Terms\")\n",
    "\n",
    "        # Log figure to wandb\n",
    "        plots[\"Missing Terms\"] = fig\n",
    "\n",
    "        return plots\n",
    "\n",
    "plotter = LV_Plotter(t, X, t_d, X_d, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training...\n",
      "Running on: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: megajosni. Use `wandb login --relogin` to force relogin\n",
      "wandb: WARNING Path <TemporaryDirectory 'C:\\\\Users\\\\jonas\\\\AppData\\\\Local\\\\Temp\\\\tmp868prn7c'>\\wandb\\ wasn't writable, using system temp directory.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\jonas\\AppData\\Local\\Temp\\wandb\\run-20241213_203512-wkqt59qh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/megajosni/Master-Thesis/runs/wkqt59qh' target=\"_blank\">UPINN</a></strong> to <a href='https://wandb.ai/megajosni/Master-Thesis' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/megajosni/Master-Thesis' target=\"_blank\">https://wandb.ai/megajosni/Master-Thesis</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/megajosni/Master-Thesis/runs/wkqt59qh' target=\"_blank\">https://wandb.ai/megajosni/Master-Thesis/runs/wkqt59qh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_points = t_d.unsqueeze(-1)\n",
    "data_target = X_d\n",
    "\n",
    "boundary_points = torch.zeros(1, 1)\n",
    "\n",
    "collocation_points = t.unsqueeze(-1).requires_grad_(True)\n",
    "\n",
    "upinn.train(\n",
    "    data_points,\n",
    "    data_target,\n",
    "    boundary_points,\n",
    "    collocation_points,\n",
    "    epochs=10000,\n",
    "    log_wandb=dict(name='UPINN', project='Master-Thesis', plotter=plotter, plot_interval=1000),\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    optimizer_args=dict(lr=0.0028621743872566546, weight_decay=0.00000000034746604191),\n",
    "    beta_softadapt=0.0,\n",
    "    # scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "    # scheduler_args=dict(factor=0.5, patience=100, min_lr=1e-6),\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
