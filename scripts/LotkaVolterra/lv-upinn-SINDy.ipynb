{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "import pysindy as ps\n",
    "\n",
    "# Add the parent directory of the script (i.e., project/) to sys.path\n",
    "sys.path.append('../../utils')\n",
    "from architectures import FNN\n",
    "from upinn import UPINN, NullWork\n",
    "from utils import SINDy_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LV_UPINN(UPINN):\n",
    "\n",
    "    def F_input(self, z, U):\n",
    "        return U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info]: Initializing UPINN model\n"
     ]
    }
   ],
   "source": [
    "# Define model architectures\n",
    "hidden = [16] * 4\n",
    "u = FNN(\n",
    "    dims=[1, *hidden, 2],\n",
    "    hidden_act=torch.nn.Tanh(),\n",
    "    output_act=torch.nn.SiLU(),\n",
    ")\n",
    "F = FNN(\n",
    "    dims=[2, *hidden, 2],\n",
    "    hidden_act=torch.nn.Tanh(),\n",
    "    output_act=torch.nn.Identity(),\n",
    ")\n",
    "\n",
    "N = NullWork()\n",
    "\n",
    "model = LV_UPINN(u, N, F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'models'\n",
    "name = 'lv_baseline_data20_noise0000'\n",
    "model.load(name, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data from the solution network\n",
    "# t = data.t_full\n",
    "t = torch.linspace(0, 10, 1000).reshape(-1, 1)\n",
    "X = model.u(t)\n",
    "X_dot = model.F(model.F_input(None, X))\n",
    "t = t.detach().numpy()\n",
    "X = X.detach().numpy()\n",
    "X_dot = X_dot.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(x)' = 1.333 x y\n",
      "(y)' = -1.000 x y\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning using Crossvalidation with TimeSeriesSplit\n",
    "sindy_model = SINDy_sklearn(feature_names=['x', 'y'], feature_library=ps.PolynomialLibrary(degree=2, include_bias=False), optimizer=ps.SR3(thresholder=\"L0\", max_iter=10000, normalize_columns=True))\n",
    "paramgrid = dict(optimizer__threshold=np.linspace(0.01, 10.0, 100))\n",
    "\n",
    "cv_folds = TimeSeriesSplit(n_splits=10)\n",
    "model_selector = GridSearchCV(sindy_model, param_grid=paramgrid, cv=cv_folds, n_jobs=-1)\n",
    "wrapped_input = np.concatenate([t, X], axis=1)\n",
    "model_selector.fit(wrapped_input, X_dot)\n",
    "best_model = model_selector.best_estimator_\n",
    "\n",
    "best_model.print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
