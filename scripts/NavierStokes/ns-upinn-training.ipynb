{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant imports\n",
    "import torch\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from kan import KAN\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Add the parent directory of the script (i.e., project/) to sys.path\n",
    "sys.path.append('../../utils')\n",
    "from upinn import UPINN\n",
    "from architectures import FNN, StackedNN, ResNet, count_parameters\n",
    "from utils import RAD_sampler, sample_collocation_points\n",
    "from NavierStokesData import NavierStokesData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data points\n",
    "data = NavierStokesData(samplesize=2000, noise_level=0.01)\n",
    "Zd = data.Zd\n",
    "Ud = data.Ud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collocation points\n",
    "N_coll = 10000\n",
    "Xc = sample_collocation_points(N_coll, 3, [1, -2, 0], [8, 2, 20], method='sobol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grad(outputs, inputs):\n",
    "    return torch.autograd.grad(outputs, inputs, grad_outputs=torch.ones_like(outputs), create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "class NavierStokes(torch.nn.Module):\n",
    "    def __init__(self, lambda1, lambda2):\n",
    "        super(NavierStokes, self).__init__()\n",
    "        self.lambda1 = lambda1\n",
    "        self.lambda2 = lambda2\n",
    "\n",
    "\n",
    "    def forward(self, Z, U):\n",
    "\n",
    "        psi = U[:, 0:1]\n",
    "        p = U[:, 1:2]\n",
    "\n",
    "        U_z = compute_grad(psi, Z)\n",
    "\n",
    "        psi_x = U_z[:, 0:1]\n",
    "        psi_y = U_z[:, 1:2]\n",
    "\n",
    "        u = psi_y\n",
    "        v = -psi_x\n",
    "\n",
    "        u_z = compute_grad(u, Z)\n",
    "        u_x = u_z[:, 0:1]\n",
    "        u_y = u_z[:, 1:2]\n",
    "        u_t = u_z[:, 2:3]\n",
    "\n",
    "        v_z = compute_grad(v, Z)\n",
    "        v_x = v_z[:, 0:1]\n",
    "        v_y = v_z[:, 1:2]\n",
    "        v_t = v_z[:, 2:3]\n",
    "\n",
    "        p_z = compute_grad(p, Z)\n",
    "        p_x = p_z[:, 0:1]\n",
    "        p_y = p_z[:, 1:2]\n",
    "\n",
    "        u_xx = compute_grad(u_x, Z)[:, 0:1]\n",
    "        u_yy = compute_grad(u_y, Z)[:, 1:2]\n",
    "\n",
    "        v_xx = compute_grad(v_x, Z)[:, 0:1]\n",
    "        v_yy = compute_grad(v_y, Z)[:, 1:2]\n",
    "\n",
    "        f = u_t + self.lambda1 * (u * u_x + v * u_y) + p_x # - self.lambda2 * (u_xx + u_yy)\n",
    "        g = v_t + self.lambda1 * (u * v_x + v * v_y) + p_y # - self.lambda2 * (v_xx + v_yy)\n",
    "\n",
    "        return torch.cat([f, g], dim=1)\n",
    "\n",
    "lambda1 = 1.0\n",
    "lambda2 = 0.01\n",
    "\n",
    "N = NavierStokes(lambda1, lambda2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NavierStokesUPINN(UPINN):\n",
    "    \n",
    "    def score(self):\n",
    "\n",
    "        Xtest = data.Zd_full.requires_grad_(True)\n",
    "\n",
    "        U_pred = self.u(Xtest)\n",
    "        psi_z = compute_grad(U_pred[:, 0], Xtest)\n",
    "        psi_y = psi_z[:, 1:2]\n",
    "        psi_x = psi_z[:, 0:1]\n",
    "\n",
    "        data_pred = torch.cat([psi_y, -psi_x], dim=1)\n",
    "        data_true = data.Ud_full[:, 0:2]\n",
    "\n",
    "        L2_rel_error = torch.sqrt(torch.mean((data_pred - data_true)**2) / torch.mean(data_true**2))\n",
    "\n",
    "        print(torch.nn.MSELoss()(data_pred, data_true).item())\n",
    "\n",
    "        return L2_rel_error.item()\n",
    "    \n",
    "\n",
    "    def score_residual(self):\n",
    "        \n",
    "        # Expected residual\n",
    "        x = torch.linspace(1, 8, 30)\n",
    "        y = torch.linspace(-2, 2, 30)\n",
    "        t = torch.linspace(0, 20, 30)\n",
    "\n",
    "        Z = torch.cartesian_prod(x, y, t).requires_grad_(True)\n",
    "\n",
    "        U_pred = self.u(Z)\n",
    "        psi_z = compute_grad(U_pred[:, 0], Z)\n",
    "        psi_y = psi_z[:, 1:2]\n",
    "        psi_x = psi_z[:, 0:1]\n",
    "\n",
    "        u_pred = psi_y\n",
    "        v_pred = -psi_x\n",
    "\n",
    "        u_z = compute_grad(u_pred, Z)\n",
    "        u_x = u_z[:, 0:1]\n",
    "        u_y = u_z[:, 1:2]\n",
    "\n",
    "        v_z = compute_grad(v_pred, Z)\n",
    "        v_x = v_z[:, 0:1]\n",
    "        v_y = v_z[:, 1:2]\n",
    "\n",
    "        u_xx = compute_grad(u_x, Z)[:, 0:1]\n",
    "        u_yy = compute_grad(u_y, Z)[:, 1:2]\n",
    "\n",
    "        v_xx = compute_grad(v_x, Z)[:, 0:1]\n",
    "        v_yy = compute_grad(v_y, Z)[:, 1:2]\n",
    "\n",
    "        res_exp_f = - lambda2 * (u_xx + u_yy)\n",
    "        res_exp_g = - lambda2 * (v_xx + v_yy)\n",
    "        res_exp = torch.cat([res_exp_f.reshape(-1,1), res_exp_g.reshape(-1,1)], dim=1)\n",
    "\n",
    "        # Predicted residual\n",
    "        res_pred = self.F(self.F_input(Z, U_pred))\n",
    "\n",
    "        # Residual MSE\n",
    "        # residual_loss = torch.mean((res_exp - res_pred)**2)\n",
    "        print(torch.mean((res_exp - res_pred)**2).item())\n",
    "        print(torch.corrcoef(torch.cat([res_exp[:, 0], res_pred[:, 0]])).item())\n",
    "        print(torch.corrcoef(torch.cat([res_exp[:, 1], res_pred[:, 1]])).item())\n",
    "\n",
    "        # temp = data.get_quantities(self)\n",
    "\n",
    "        # f_res_true = temp[\"f_res_true\"]\n",
    "        # g_res_true = temp[\"g_res_true\"]\n",
    "\n",
    "        # f_res_exp = temp[\"f_res_exp\"]\n",
    "        # g_res_exp = temp[\"g_res_exp\"]\n",
    "\n",
    "        # f_res_pred = temp[\"f_res_pred\"]\n",
    "        # g_res_pred = temp[\"g_res_pred\"]\n",
    "\n",
    "        # print('True:', np.sqrt((np.mean((f_res_true - f_res_pred)**2) + np.mean((g_res_true - g_res_pred)**2)) / (np.mean(f_res_true**2) + np.mean(g_res_true**2)))) \n",
    "\n",
    "        L2_rel_error = torch.sqrt(torch.mean((res_exp - res_pred)**2) / torch.mean(res_exp**2))\n",
    "        return L2_rel_error.item()\n",
    "\n",
    "\n",
    "    def data_loss(self):\n",
    "\n",
    "        if self.data_points is not None:\n",
    "            \n",
    "            self.data_points[0].requires_grad_(True)\n",
    "\n",
    "            Ud = self.u(self.data_points[0])\n",
    "\n",
    "            psi_z = compute_grad(Ud[:, 0], self.data_points[0])\n",
    "            psi_y = psi_z[:, 1:2]\n",
    "            psi_x = psi_z[:, 0:1]\n",
    "\n",
    "            # data_pred = torch.cat([psi_y, -psi_x], dim=1)\n",
    "            # data_loss = torch.mean((data_pred - self.data_points[1][:, 0:2])**2)\n",
    "\n",
    "            data_pred = torch.cat([psi_y, -psi_x, Ud[:, 1:2]], dim=1)\n",
    "            data_loss = torch.mean((data_pred - self.data_points[1][:, 0:3])**2)\n",
    "\n",
    "            # self.log.setdefault(\"lambda1\", []).append(lambda1.item())\n",
    "            # self.log.setdefault(\"lambda2\", []).append(lambda2.item())\n",
    "\n",
    "        else: data_loss = torch.tensor(0.0)\n",
    "\n",
    "        return data_loss\n",
    "    \n",
    "    def F_input(self, Z, U):\n",
    "        \n",
    "        psi = U[:, 0:1]\n",
    "        \n",
    "        U_z = compute_grad(psi, Z)\n",
    "\n",
    "        psi_x = U_z[:, 0:1]\n",
    "        psi_y = U_z[:, 1:2]\n",
    "\n",
    "        u = psi_y\n",
    "        v = -psi_x\n",
    "\n",
    "        if not self.inductive_bias:\n",
    "            return torch.cat([Z, u, v], dim=1)\n",
    "        else:\n",
    "\n",
    "            u_z = compute_grad(u, Z)\n",
    "            u_x = u_z[:, 0:1]\n",
    "            u_y = u_z[:, 1:2]\n",
    "\n",
    "            v_z = compute_grad(v, Z)\n",
    "            v_x = v_z[:, 0:1]\n",
    "            v_y = v_z[:, 1:2]\n",
    "\n",
    "            u_xx = compute_grad(u_x, Z)[:, 0:1]\n",
    "            u_yy = compute_grad(u_y, Z)[:, 1:2]\n",
    "\n",
    "            v_xx = compute_grad(v_x, Z)[:, 0:1]\n",
    "            v_yy = compute_grad(v_y, Z)[:, 1:2]\n",
    "\n",
    "            u_xy = compute_grad(u_x, Z)[:, 1:2]\n",
    "            v_xy = compute_grad(v_x, Z)[:, 1:2]\n",
    "\n",
    "            return torch.cat([u, v, u_x, u_y, v_x, v_y, u_xy, v_xy, u_xx, u_yy, v_xx, v_yy], dim=1)\n",
    "\n",
    "\n",
    "\n",
    "    # def refine_collocation_points(self):\n",
    "    #     N = 10*N_coll\n",
    "    #     D = N_coll\n",
    "    #     k = 0.5\n",
    "    #     c = 0.1\n",
    "\n",
    "    #     device = self.device\n",
    "    #     Xc = sample_collocation_points(N, 3, lb=[1, -2, 0], ub=[8, 2, 20], method='sobol').requires_grad_(True).to(device)\n",
    "\n",
    "    #     self.to(device)\n",
    "\n",
    "    #     # Compute the residual\n",
    "    #     U = self.u(Xc)\n",
    "    #     residual = torch.sum(torch.abs(self.F(self.F_input(Xc, U)) + self.N(Xc, U)), dim=1)\n",
    "\n",
    "    #     self.to('cpu')\n",
    "\n",
    "    #     self.collocation_points = RAD_sampler(Xc, residual, D, k, c) # RAD\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_u = [64] * 8\n",
    "\n",
    "u = FNN(\n",
    "    dims=[3, *hidden_u, 2],\n",
    "    hidden_act=torch.nn.Tanh(),\n",
    "    output_act=torch.nn.Identity(),\n",
    ")\n",
    "\n",
    "hidden_F = [64] * 8\n",
    "\n",
    "F = FNN(\n",
    "    dims=[5, *hidden_F, 2],\n",
    "    hidden_act=torch.nn.Tanh(),\n",
    "    output_act=torch.nn.Identity(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u = ResNet(\n",
    "#     input_dim=3, hidden_dim=40, output_dim=2, num_blocks=4, block_size=2,\n",
    "# )\n",
    "\n",
    "# F = ResNet(\n",
    "#     input_dim=5, hidden_dim=40, output_dim=2, num_blocks=4, block_size=2,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u1 = FNN(\n",
    "#     dims=[3, *hidden, 1],\n",
    "#     hidden_act=torch.nn.Tanh(),\n",
    "#     output_act=torch.nn.Identity(),\n",
    "# )\n",
    "\n",
    "# u2 = FNN(\n",
    "#     dims=[3, *hidden, 1],\n",
    "#     hidden_act=torch.nn.Tanh(),\n",
    "#     output_act=torch.nn.Identity(),\n",
    "# )\n",
    "\n",
    "# u = StackedNN([u1, u2])\n",
    "\n",
    "# F1 = FNN(\n",
    "#     dims=[5, *hidden, 1],\n",
    "#     hidden_act=torch.nn.Tanh(),\n",
    "#     output_act=torch.nn.Identity(),\n",
    "# )\n",
    "\n",
    "# F2 = FNN(\n",
    "#     dims=[5, *hidden, 1],\n",
    "#     hidden_act=torch.nn.Tanh(),\n",
    "#     output_act=torch.nn.Identity(),\n",
    "# )\n",
    "\n",
    "# F = StackedNN([F1, F2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hidden = [4] * 4\n",
    "\n",
    "# u = KAN([3, *hidden, 2])\n",
    "# F = KAN([5, *hidden, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info]: Initializing UPINN model\n"
     ]
    }
   ],
   "source": [
    "model = NavierStokesUPINN(u, N, F, data_points=(Zd, Ud), collocation_points=Xc)\n",
    "model.inductive_bias = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.softadapt_kwargs = dict(beta=0.05, loss_weigthed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(adam, step_size=500, gamma=0.8)\n",
    "lbfgs = torch.optim.LBFGS(model.parameters(), lr=1e-1)\n",
    "\n",
    "model.scheduler = scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_loop(2000, optimizer=adam)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
